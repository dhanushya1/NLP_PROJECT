{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sanchana\n",
      "[nltk_data]     M\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Sanchana\n",
      "[nltk_data]     M\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Review_id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PES UNIVERSITY</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Placements: Almost 90% of students got placed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PES UNIVERSITY</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Placements: Our college is the best for placem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PES UNIVERSITY</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Placements: Students are not recruited in our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PES UNIVERSITY</td>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Placements: Almost 95% of students got placed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PES UNIVERSITY</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Placements: In the 2021 batch, the salary pack...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Review_id  Rating  \\\n",
       "0  PES UNIVERSITY          1     4.4   \n",
       "1  PES UNIVERSITY          2     4.6   \n",
       "2  PES UNIVERSITY          3     3.8   \n",
       "3  PES UNIVERSITY          4     4.6   \n",
       "4  PES UNIVERSITY          5     4.0   \n",
       "\n",
       "                                              Review  \n",
       "0  Placements: Almost 90% of students got placed ...  \n",
       "1  Placements: Our college is the best for placem...  \n",
       "2  Placements: Students are not recruited in our ...  \n",
       "3  Placements: Almost 95% of students got placed ...  \n",
       "4  Placements: In the 2021 batch, the salary pack...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting reviews into features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Placement ={}\n",
    "Infrastructure={}\n",
    "Faculty={}\n",
    "Other = {}\n",
    "\n",
    "for i in range(100):\n",
    "    college = data.iloc[i,0]\n",
    "    review = data.iloc[i,3]\n",
    "    if college not in Placement:\n",
    "        Placement[college]=list()\n",
    "        Infrastructure[college]=list()\n",
    "        Faculty[college]=list()\n",
    "        Other[college]=list()\n",
    "    rev_list = re.split('\\n',review)\n",
    "    Placement[college].append(rev_list[0][12:])\n",
    "    Infrastructure[college].append(rev_list[2][15:])\n",
    "    Faculty[college].append(rev_list[4][8:])\n",
    "    if len(rev_list)==7:\n",
    "        Other[college].append(rev_list[6][7:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(text):\n",
    "    \n",
    "    sentences =[]\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        sentence.replace(\"[^a-zA-Z0-9]\",\" \")\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1,sent2,stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    \n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    #build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if not w in stopwords:\n",
    "            vector1[all_words.index(w)]+=1\n",
    "    \n",
    "    #build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if not w in stopwords:\n",
    "            vector2[all_words.index(w)]+=1\n",
    "            \n",
    "    return 1-cosine_distance(vector1,vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences,stop_words):\n",
    "    #create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences),len(sentences)))\n",
    "    \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1!=idx2:\n",
    "                similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],sentences[idx2],stop_words)\n",
    "                \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text,top_n):\n",
    "    \n",
    "\n",
    "    summarize_text = []\n",
    "    \n",
    "    # Step1: read text and tokenize\n",
    "    sentences = read_article(text)\n",
    "    sentences= [*set(sentences)]\n",
    "    # Steo2: generate similarity matrix across sentences\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences,stop_words)\n",
    "    \n",
    "    # Step3: Rank sentences in similarirty matrix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "    \n",
    "    #Step4: sort the rank and place top sentences\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)),reverse=True)\n",
    "    \n",
    "    # Step 5: get the top n number of sentences based on rank    \n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(ranked_sentences[i][1])\n",
    "    \n",
    "    # Step 6 : outpur the summarized version\n",
    "    return \"\\n\".join(summarize_text),len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placements: More than 90% of students get placed every year with good salary packages.\n",
      "The salary package offered ranges between 3 LPA - 40 LPA.\n",
      "Around 300 students out of 350 got placed in very good companies and rest all opted for higher studies.\n",
      "Infrastructure: Infrastructure is good and well framed with respect to many centres providing ample of opportunities for the students to create a different vibes Hostel facility are also good providing students to outsource all the college facilities such as gymnastics sports practice libraries etc.\n",
      "The library facility is very good in our college with a very wide range of books.\n",
      "Hostels were not good but the food served was good and delicious.\n",
      "Faculty: Hence their course content is up to date The exams are pretty difficult- they are based solely on the concepts taught in class.\n",
      "The course curriculum is relevant and helpful to the students when it comes to placements.\n",
      "Semester exams are quite difficult, and we do not have any internal choice in the question papers.\n",
      "Other: Our college should provide more placements in CSE or ECE branches.\n",
      "I opted for this course because the future depends on automatic things, so there is demand for this course.\n",
      "Events, fests, the campus crowd, campus surroundings, and the environment are very good compared to other colleges.\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(Placement[\"Reva University\"])\n",
    "print(\"Placements: \"+generate_summary(text,3)[0])\n",
    "text = ' '.join(Infrastructure[\"Reva University\"])\n",
    "print(\"Infrastructure: \"+generate_summary(text,3)[0])\n",
    "lol = ' '.join(Faculty[\"PES UNIVERSITY\"])\n",
    "print(\"Faculty: \"+generate_summary(lol,3)[0])\n",
    "text = ' '.join(Other[\"Reva University\"])\n",
    "print(\"Other: \"+generate_summary(text,3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
